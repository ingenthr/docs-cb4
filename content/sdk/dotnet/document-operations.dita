<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="document-operations-dotnet">
    <title>Document Operations</title>
    <body>

    <p> You can access documents in Couchbase using methods of the
        <apiname>Couchbase.CouchbaseBucket</apiname> object. The methods for retrieving documents
      are <apiname>Get&lt;T>()</apiname> and <apiname>LookupIn&lt;TDocument>()</apiname> and the
      methods for mutating documents are <apiname>Upsert&lt;T>()</apiname>,
        <apiname>Insert&lt;T>()</apiname>, <apiname>Replace&lt;T>()</apiname> and
        <apiname>MutateIn&lt;TDocument>()</apiname>. </p>
    <p> Examples are shown using the synchronous methods. See the section on <xref
        href="async-programming.dita">Async Programming</xref> for information on other methods. </p>

    <section id="dotnet-additional-options">
        <title>Additional options</title>
        <p> Update operations also accept a <xref
          href="../core-operations.dita#devguide_kvcore_generic/expiry">TTL
          (expiry)</xref> value (<parmname>Expiry</parmname>) on the passed <parmname>IDocument</parmname> which will
        instruct the server to delete the document after a given amount of time. This option is
        useful for transient data (such as sessions). By default documents do not expire. See <xref
          href="../core-operations.dita#devguide_kvcore_generic/expiry"/> for more
        information on expiration. </p>
        <p> Update operations can also accept a <xref
          href="../concurrent-mutations-cluster.dita">CAS</xref> (<parmname>Cas</parmname>)
        value on the passed document to protect against concurrent updates to the same document. See
          <xref href="../concurrent-mutations-cluster.dita">CAS</xref> for a description on
        how to use CAS values in your application. Since CAS values are opaque, they are normally
        retreived when a Document is loaded from Couchbase and then used subsequently (without
        modification) on the mutation operations. If a mutation did succeed, the returned Document
        will contain the new CAS value. </p>
    </section>

    <section id="dotnet-mutation-input">
        <title>Document input and output types</title>
        <p>
            Couchbase stores documents. From an SDK point of view, those
            documents contain the actual value (like a JSON object) and
            associated metadata. Every document in the Java SDK contains
            the following properties, some of them optional depending on
            the context:
        </p>
        <table>
          <tgroup cols="2">
            <thead>
              <row>
                <entry>Name</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                <codeph>Id</codeph>
              </entry>
                <entry>The (per bucket) unique identifier of the document.</entry>
              </row>
              <row>
                <entry>
                <codeph>Content</codeph>
              </entry>
                <entry>The actual content of the document.</entry>
              </row>
              <row>
                <entry>
                <codeph>Cas</codeph>
              </entry>
                <entry>The CAS (Compare And Swap) value of the document.</entry>
              </row>
              <row>
                <entry>
                <codeph>Expiry</codeph>
              </entry>
                <entry>The expiration time of the document.</entry>
              </row>
              <row>
                <entry>
                <codeph>Token</codeph>
              </entry>
                <entry>The optional MutationToken after a mutation.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
        <p> There are a few different results using <codeph>IDocument</codeph> you may encounter: <ul>
          <li><apiname>Document</apiname>: The default one in most methods and is backed by a JSON
            document when stored to Couchbase.  Commonly this is a
              <apiname>Document&lt;dynamic></apiname> object, which the API will handle
            automatically on behalf of your program.</li>
          <li><apiname>DocumentResult</apiname>: The return type for any
              <apiname>IDocument</apiname> centric operation requests.</li>
          <li><apiname>OperationResult&lt;T></apiname>: The return type for any binary operations
            that return a value. See <xref href="#document-operations/dotnet-binary-document">the
              section about binary documents</xref>.  TODO: fix xref.</li>
        </ul>
      </p>
        <p>Because Couchbase Server can store anything and not just JSON, there is the possibility
        for other implementations of the <apiname>IDocument</apiname> interface or the
          <apiname>IOperationResult</apiname> interface.  These are usually returned by other
        methods on the <apiname>Bucket</apiname> or are implemented using an <apiname>ITypeTranscoder</apiname>, which is
        outside the scope of this inroduction.</p>
    </section>

    <section id="dotnet-creating-updating-full-docs">
        <title>Creating and updating full documents</title>
        <p> Documents may be created and updated using the <apiname>Bucket#Upsert&lt;T>()</apiname>,
          <apiname>Bucket#Insert&lt;T>()</apiname>, and <apiname>Bucket#Replace&lt;T>()</apiname>
        family of methods. Read more about the difference between these methods at <xref
          href="../core-operations.dita#devguide_kvcore_generic/crud-overview"/> in
        the Couchbase developer guide. </p>

        <p> These methods accept an IDocument instance where the following properties are considered
        if set: <ul>
          <li><parmname>Id</parmname> (mandatory): The ID of the document to modify (String).</li>
          <li><parmname>Content</parmname> (mandatory): The desired new content of the document,
            this varies per document type used. If the <codeph>JsonDocument</codeph> is used, the
            document type is a <codeph>JsonObject</codeph>.</li>
          <li><parmname>Expiry</parmname> (optional): Specify the expiry time for the document. If
            specified, the document will expire and no longer exist after the given number of
            seconds. See <xref href="../core-operations.dita#expiry"/> for more
            information.</li>
          <li><parmname>Cas</parmname> (optional): The CAS value for the document. If the CAS on the
            server does not match the CAS supplied to the method, the operation will fail with a
              <apiname>CASMismatchException</apiname>. See <xref
              href="../concurrent-mutations-cluster.dita"/> for more information on the usage
            of CAS values.  Note that the <codeph>Cas</codeph> is represented here as a <apiname>UInt64</apiname>,
            but you should consider it an opaque value in your programs.</li>
        </ul>
      </p>

        <p> Other optional arguments are also available for more advanced usage: <ul>
          <li><parmname>TimeSpan</parmname>: A value for the <apiname>Expiry</apiname> on this
            document.</li>
          <li><parmname>PersistTo</parmname>, <parmname>ReplicateTo</parmname>: Specify <xref
              href="../durability.dita#concept_gyg_14s_zs"> durability
              requirements</xref> for the operations.</li>
        </ul></p>
        <p> Upon success, the returned <apiname>IDocumentResult</apiname> instance will contain the
        new <xref href="../concurrent-mutations-cluster.dita#concept_iq4_bts_zs">CAS</xref>
        value of the document. If the document is not mutated successfully, an exception is raised
        depending on the type of error.   Further details on the exceptional case may be on the
          <parmname>Exception</parmname> property of the returned
          <parmname>IDocumentResult</parmname>.</p>
        <p>Inserting a document works like this:</p>

        <codeblock outputclass="language-csharp"><![CDATA[﻿            var doc = new Document<dynamic>
            {
                Id = "document_id",
                Content = new
                {
                    some = "value"
                }
            };
            var result = _bucket.Insert(doc);
            Console.WriteLine(result.Success);]]></codeblock>

<screen>Output: True</screen>

        <p>
            If the same code is called again, a
            <codeph>False</codeph> will be
            returned. If you don't care that the document is overwritten,
            you can use <apiname>upsert</apiname> instead:
        </p>

        <codeblock outputclass="language-csharp"><![CDATA[﻿            doc = new Document<dynamic>
            {
                Id = "document_id",
                Content = new
                {
                    some = "other value"
                }
            };
            result = _bucket.Upsert(doc);
            Console.WriteLine(result.Success);]]></codeblock>

<screen>Output: True</screen>


        <p>
            Finally, a full document can be replaced if it existed
            before. If it didn't exist, then a
            <codeph>False</codeph> will be
            returned in the <codeph>IDocument.Success</codeph>:
        </p>

        <codeblock outputclass="language-csharp"><![CDATA[﻿            result = _bucket.Replace(doc);
            Console.WriteLine(result.Success);]]></codeblock>

<screen>Output: True</screen>

    </section>

    <section id="dotnet-retrieving-full-docs">
            <title>Retrieving full documents</title>
            <p> Documents may be retrieved using <apiname>Bucket#GetDocument&lt;T&gt;()</apiname>.
                You may also retrieve items from the or the <apiname>Bucket#Get&lt;T&gt;()</apiname>
                method. The former is for situaitons where you want an
                    <codeph>IDocumentResult</codeph> and the latter for situations where you want an
                    <codeph>IOperationResult</codeph></p>
            <p> Most of the time you use the <apiname>GetDocument()</apiname> method. It accepts one
                mandatory argument: </p>
            <ul>
                <li><parmname>key</parmname>: The document ID (or key) to retrieve</li>
            </ul>s <codeblock outputclass="language-csharp"><![CDATA[﻿            var getRes = _bucket.GetDocument<dynamic>("document_id");
            Console.WriteLine(getRes.Document.Content);]]></codeblock>
            <screen>Output: ﻿{
  "some": "other value"
}</screen>
            <!-- TODO: add a discussion of the Get() and the IOperationResult interface -->
            <p> It is possible to read from a replica if you want to explicitly trade availability
                for consistency during the timeframe when the active partition is not reachable (for
                example during a node failure or netsplit). </p>
            <p><codeph>GetFromReplica</codeph> has one mandatory argument as well:</p>
            <ul>
                <li><parmname>key</parmname>: The document ID (or key) to retrieve</li>
            </ul>
            <!-- TODO: need to enhancet this with a description of how this works <p>
            Since you can have 0 to 3 replicas (and they can change at
            runtime of your application) the
            <codeph>GetFromReplica</codeph> returns Lists or Iterators.
            It is recommended to use the Iterator APIs since they
            provide more flexibility during error conditions (since only
            partial responses may be retreived).
        </p>

<codeblock outputclass="language-java"><![CDATA[Iterator<JsonDocument> docIter = bucket.getFromReplica("document_id");
while(docIter.hasNext()) {
    JsonDocument replicaDoc = docIter.next();
    System.out.println(replicaDoc);
}]]></codeblock> -->
            <note type="important"> Since a replica is updated asynchronously and eventually
                consistent, reading from it may return stale and/or outdated results! </note>
            <p> If you need to use pessimistic write locking on a document you can use the
                    <parmname>GetAndLock</parmname> which will retreive the document if it exists
                and also return its <parmname>CAS</parmname> value. You need to provide a time that
                the document is maximum locked (and the server will unlock it then) if you don't
                update it with the valid cas. Also note that this is a pure write lock, reading is
                still allowed. </p>
            <!-- TODO: write a sample for this.  I tried one at https://gist.github.com/ingenthr/ac1a72090528c3438dda764cf36d3f9c but failed -->
            <codeblock outputclass="language-java"><![CDATA[﻿            // Get and Lock for max of 10 seconds
            var ownedDoc = _bucket.GetWithLock<dynamic>("document_id", 10);

            // Do something with your document
            ReplacementDocument modifiedDoc = modifyDocument<IDocument>(ownedDoc);

            // Write it back with the correct CAS
            var replaceResponse = _bucket.Replace(modifiedDoc);
            Console.WriteLine("Replace success? "+ replaceResponse.Success);]]></codeblock>
            <p>This uses a private method and a class implementing <codeph>IDocument</codeph></p>
        <codeblock>﻿<![CDATA[﻿        private ReplacementDocument modifyDocument<T>(IOperationResult<dynamic> ownedDoc)
        {
            var response =  new ReplacementDocument("document_id", ownedDoc);
            return response;
        }

        ﻿    class ReplacementDocument : IDocument<object>
    {
        public ulong Cas { get; }
        public dynamic Content { get; private set; }
        public int Expiry { get; private set; }
        public string Id { get; private set; }

        private IOperationResult<dynamic> ownedDoc;


        public ReplacementDocument(String id, IOperationResult<dynamic> ownedDoc)
        {
            this.ownedDoc = ownedDoc;
            this.Cas = ownedDoc.Cas;
            this.Content = ownedDoc.Value;
            this.Expiry = 0;
            this.Id = id;

        }
    }

        ]]></codeblock>
            <p> If the document is locked already and you are trying to lock it again, the response
                will have <codeph>False</codeph> for <codeph>Success</codeph> and additional information in the <codeph>Message</codeph>.</p>
        </section>

    <section id="dotnet-removing-full-docs">
        <title>Removing full documents</title>

        <p>
            Documents may be removed using the
            <apiname>Bucket.remove()</apiname> method. This method takes
            a single mandatory argument:
        </p>
        <ul>
            <li><parmname>id</parmname>: The ID of the document to remove.</li>
        </ul>

        <p>Some additional options:</p>
        <ul>
            <li><parmname>persistTo</parmname>, <parmname>replicateTo</parmname>: Specify
                    <xref href="../durability.dita#concept_gyg_14s_zs"
                    >durability requirements</xref> for the operations.</li>
            <li><parmname>timeout</parmname>, <parmname>timeUnit</parmname>: Specify a custom
            timeout which overrides the default timeout setting.</li>
        </ul>

        <p>
            If the <codeph>cas</codeph> value is set on the Document
            overload, it is used to provide optimistic currency, very
            much like the <codeph>replace</codeph> operation.
        </p>

<codeblock outputclass="language-java"><![CDATA[// Remove the document
JsonDocument removed = bucket.remove("document_id");]]></codeblock>

<codeblock outputclass="language-java"><![CDATA[JsonDocument loaded = bucket.get("document_id");

// Remove and take the CAS into account
JsonDocument removed = bucket.remove(loaded);]]></codeblock>

    </section>

    <section id="dotnet-modifying-expiration">
        <title>Modifying expiraton</title>

        <p>
            Modifying the
            <xref href="../core-operations.dita#devguide_kvcore_generic/expiry">Document expiration</xref>
            can be performed using the <apiname>Bucket#touch()</apiname>
            method. In addition, many methods support setting the expiry
            value as part of their other primary operations:
        </p>

        <ul>
            <li><apiname>Bucket#touch</apiname>: Resets the expiry time for the given document ID to the value provided.</li>
            <li><apiname>Bucket#getAndTouch</apiname>: Fetches the document and resets the expiry to the given value provided.</li>
            <li><apiname>Bucket#insert</apiname>, <apiname>Bucket#upsert</apiname>, <apiname>Bucket#replace</apiname>: Stores
            the expiry value alongside the actual mutation when set on the <codeph>Document</codeph> instance.</li>
        </ul>

        <p>
            The following example stores a document with an expiry,
            waits a bit longer and as a result no document is found
            on the subsequent get:
        </p>

<codeblock outputclass="language-java"><![CDATA[int expiry = 2; // seconds
JsonDocument stored = bucket.upsert(
    JsonDocument.create("expires", expiry, JsonObject.create().put("some", "value"))
);

Thread.sleep(3000);

System.out.println(bucket.get("expires"));]]></codeblock>

<screen>null</screen>

    </section>

    <section id="dotnet-atomic-modifications">
        <title>Atomic document modifications</title>

        Additional atomic document modifications can be performing using
        the Java SDK. You can modify a
        <xref href="../core-operations.dita#devguide_kvcore_generic/devguide_kvcore_counter_generic" >counter document</xref>
        using the <apiname>Bucket.counter()</apiname> method. You can
        also use the <apiname>Bucket.append()</apiname> and
        <apiname>Bucket.prepend()</apiname> methods to perform
        <xref href="../core-operations.dita#devguide_kvcore_generic/devguide_kvcore_append_prepend_generic" >raw byte concatenation</xref>.
    </section>

    <section id="dotnet-batching-ops">
        <title>Batching Operations</title>
        <p>
            Since the Java SDK uses RxJava as its asynchronous
            foundation, all operations can be
            <xref href="../batching-operations.dita#concept_qfq_5jg_1t" >batched</xref>
            in the SDK using the
            <xref href="async-programming.dita#async-programming-java"> asynchronous API</xref>
            via <codeph>bucket.async()</codeph> (and optionally revert
            back to blocking).
        </p>
        <p>
            Implicit batching is performed by utilizing a few operators:
            <codeph>Observable.just()</codeph> or
            <codeph>Observable.from()</codeph> to generate an observable
            that contains the data you want to batch on.
            <codeph>flatMap()</codeph> to send those events against the
            Couchbase Java SDK and merge the results asynchronously.
            <codeph>last()</codeph> if you want to wait until the last
            element of the batch is received. <codeph>toList()</codeph>
            if you care about the responses and want to aggregate them
            easily. If you have more than one subscriber, use
            <codeph>cache()</codeph> to prevent accessing the network
            over and over again with every subscribe.
        </p>
        <p>
            The following example creates an observable stream of 6 keys
            to load in a batch, asynchronously fires off
            <codeph>get()</codeph> requests against the SDK (notice the
            <codeph>bucket.async().get(...)</codeph>), waits until the
            last result has arrived, and then converts the result into a
            list and blocks at the very end. This pattern can be reused
            for mutations like <codeph>upsert</codeph> (as shown further
            down):
        </p>
        <codeblock outputclass="language-java"><![CDATA[Cluster cluster = CouchbaseCluster.create();
Bucket bucket = cluster.openBucket();

List<JsonDocument> foundDocs = Observable
    .just("key1", "key2", "key3", "key4", "inexistentDoc", "key5")
    .flatMap(new Func1<String, Observable<JsonDocument>>() {
        @Override
        public Observable<JsonDocument> call(String id) {
            return bucket.async().get(id);
        }
    })
    .toList()
    .toBlocking()
    .single();

for (JsonDocument doc : foundDocs) {
    System.out.println(doc.id());
}]]></codeblock>
<screen>key1
key2
key3
key4
key5</screen>
        <p>
            Note that this always returns a list, but it may contain 0
            to 6 documents (here 5) depending on how many are actually
            found. Also, at the very end the observable is converted
            into a blocking one, but everything before that, including
            the network calls and the aggregation, is happening
            completely asynchronously.
        </p>
        <p>
            Inside the SDK, this provides much more efficient resource
            utilization because the requests are very quickly stored in
            the internal Request RingBuffer and the I/O threads are able
            to pick batches as large as they can. Afterward, whatever
            server returns a result first it is stored in the list, so
            there is no serialization of responses going on.
        </p>
        <p>
            Batching mutations: The previous Java SDK only provided bulk
            operations for get(). With the techniques shown above, you
            can perform any kind of operation as a batch operation. The
            following code generates a number of fake documents and
            inserts them in one batch. Note that you can decide to
            either collect the results with <codeph>toList()</codeph> as
            shown above or just use <codeph>last()</codeph> as shown
            here to wait until the last document is properly inserted:
        </p>
<codeblock outputclass="language-java"><![CDATA[// Generate a number of dummy JSON documents
int docsToCreate = 100;
List<JsonDocument> documents = new ArrayList<JsonDocument>();
for (int i = 0; i < docsToCreate; i++) {
    JsonObject content = JsonObject.create()
        .put("counter", i)
        .put("name", "Foo Bar");
    documents.add(JsonDocument.create("doc-"+i, content));
}

// Insert them in one batch, waiting until the last one is done.
Observable
    .from(documents)
    .flatMap(new Func1<JsonDocument, Observable<JsonDocument>>() {
        @Override
        public Observable<JsonDocument> call(final JsonDocument docToInsert) {
            return bucket.async().insert(docToInsert);
        }
    })
    .last()
    .toBlocking()
    .single();]]></codeblock>
    </section>

    <section id="dotnet-subdocs">
        <title>Operating with sub-documents</title>
        <note type="tip">See <xref href="../subdocument-operations.dita#subdoc-operations"/> for an overview</note>
        <hazardstatement><messagepanel id="messagepanel_edy_qwm_qv">
            <typeofhazard>Sub-Document API is experimental</typeofhazard>
            <howtoavoid>Sub-Document is a feature to be released in Couchbase 4.5. It is available as an experimental feature in 4.5 pre-release builds.</howtoavoid>
        </messagepanel></hazardstatement>
        <p>
            Sub-document operations save network bandwidth by allowing
            you to specify <i>paths</i> of a document to be retrieved or
            updated. The document is parsed on the server and only the
            relevant sections (indicated by <i>paths</i>) are
            transferred between client and server. You can execute
            <xref href="../subdocument-operations.dita#subdoc-operations" >sub-document</xref>
            operations in the Java SDK using the
            <apiname>Bucket#lookupIn()</apiname> and
            <apiname>Bucket#mutateIn()</apiname> methods.
        </p>
        <p>
            Each of these methods accepts a <parmname>key</parmname> as
            its mandatory first argument and give you a builder that you
            can use to chain several <i>command specifications</i>, each
            specifying the path to be impacted by the specified
            operation and a document field operand. You may find all the
            operations in the <apiname>LookupInBuilder</apiname> and
            <apiname>MutateInBuilder</apiname> classes.
        </p>

<codeblock outputclass="language-java"><![CDATA[bucket.lookupIn("docid")
    .get("path.to.get")
    .exists("check.path.exists")
    .execute();

boolean createParents = true;
bucket.mutateIn("docid")
    .upsert("path.to.upsert", value, createParents)
    .remove("path.to.del"))
    .execute();]]></codeblock>

        <p>
            All sub-document operations return a special
            <apiname>DocumentFragment</apiname> object rather than a
            <apiname>Document</apiname>. It shares the
            <codeph>id()</codeph>, <codeph>cas()</codeph> and
            <codeph>mutationToken()</codeph> fields of a document, but
            in contrast with a normal <apiname>Document</apiname>
            object, a <apiname>DocumentFragment</apiname> object
            contains multiple results with multiple statuses, one
            result/status pair for every input operation. So it exposes
            method to get the <codeph>content()</codeph> and
            <codeph>status()</codeph> of each spec, either by index or
            by path. It also allows to check that a response for a
            particular spec <codeph>exists()</codeph>:
        </p>
<codeblock outputclass="language-java"><![CDATA[DocumentFragment<Lookup> res =
bucket.lookupIn("docid")
    .get("foo")
    .exists("bar")
    .exists("baz")
    .execute();
// First result
res.content("foo");
// or
res.content(0);]]></codeblock>

        <p>
            Using the <codeph>content(...)</codeph> methods will raise
            an exception if the individual spec did not complete
            successfully. You can also use the
            <codeph>status(...)</codeph> methods to return an error code
            (a <apiname>ResponseStatus</apiname>) rather than throw an
            exception.
        </p>
    </section>

    <section id="dotnet-formats-non-json">
        <title>Formats and Non-JSON Documents</title>
        <note type="tip">See <xref href="../nonjson.dita#devguide_nonjson"/> for a general overview of using non-JSON documents with Couchbase</note>
        <p>
            The Java SDK defines several concrete implementations of a
            <apiname>Document</apiname> to represent the various data
            types that it can store. Here is the complete list of
            document types:
            <table>
                <title>Documents with JSON content</title>
                <tgroup cols="2">
                <thead><row>
                    <entry>Document Name</entry><entry>Description</entry>
                </row></thead>
                <tbody>
                <row>
                    <entry><apiname>JsonDocument</apiname></entry>
                    <entry>The default, which has a <apiname>JsonObject</apiname> at the top level content.</entry>
                </row>
                <row>
                    <entry><apiname>RawJsonDocument</apiname></entry>
                    <entry>Stores any JSON value and should be used if custom JSON serializers such as Jackson or GSON are already in use.</entry>
                </row>
                <row>
                    <entry><apiname>JsonArrayDocument</apiname></entry>
                    <entry>Similar to JsonDocument, but has a <apiname>JsonArray</apiname> at the top level content.</entry>
                </row>
                <row>
                    <entry><apiname>JsonBooleanDocument</apiname></entry>
                    <entry>Stores JSON-compatible Boolean values.</entry>
                </row>
                <row>
                    <entry><apiname>JsonLongDocument</apiname></entry>
                    <entry>Stores JSON compatible long (number) values.</entry>
                </row>
                <row>
                    <entry><apiname>JsonDoubleDocument</apiname></entry>
                    <entry>Stores JSON compatible double (number) values.</entry>
                </row>
                <row>
                    <entry><apiname>JsonStringDocument</apiname></entry>
                    <entry>Stores JSON compatible <apiname>String</apiname> values. Input is automatically wrapped with quotes when stored.</entry>
                </row>
                <row>
                    <entry><apiname>EntityDocument</apiname></entry>
                    <entry>Used with the <apiname>Repository</apiname> implementation to write and read POJOs into JSON and back.</entry>
                </row>
                </tbody>
                </tgroup>
            </table>

            <table>
                <title>Documents with other content</title>
                <tgroup cols="2">
                <thead><row>
                    <entry>Document Name</entry><entry>Description</entry>
                </row></thead>
                <tbody>
                <row>
                    <entry><apiname>BinaryDocument</apiname></entry>
                    <entry>Can be used to store arbitrary binary data.</entry>
                </row>
                <row>
                    <entry><apiname>SerializableDocument</apiname></entry>
                    <entry>Stores objects that implement <apiname>Serializable</apiname> through default Java object serialization.</entry>
                </row>
                <row>
                    <entry><apiname>LegacyDocument</apiname></entry>
                    <entry>Uses the <apiname>Transcoder</apiname> from the 1.x SDKs and can be used for full cross-compatibility between the old and new versions.</entry>
                </row>
                <row>
                    <entry><apiname>StringDocument</apiname></entry>
                    <entry>Can be used to store arbitrary strings. They will not be quoted, but stored as-is and flagged as "String".</entry>
                </row>
                </tbody>
                </tgroup>
            </table>
        </p>
        <p>
            You can implement a custom document type and associated
            transcoder if none of the pre-configured options are
            suitable for your application. A custom transcoder converts
            intputs to their serialized forms, and deserializes encoded
            data based on the item flags. There is an
            <apiname>AbstractTranscoder</apiname> that can serve as the
            basis for a custom implementation, and custom transcoders
            should be registered with a <apiname>Bucket</apiname> when
            calling <apiname>Cluster#openBucket</apiname> (a list of
            custom transcoders can be passed in one of the overloads).
        </p>
    </section>

    <section id="dotnet-binary-document">
        <title>Correctly managing BinaryDocuments</title>
        <p>
            The <codeph>BinaryDocument</codeph> can be used to store and
            read arbitrary bytes. It is the only default codec that
            directly exposes the underlying low-level Netty
            <codeph>ByteBuf</codeph> objects.
        </p>
		<note type="important">
            Because the raw data is exposed, it is important to free it
            after it has been properly used. Not freeing it will result
            in increased garbage collection and memory leaks and should
            be avoided by all means. See <xref href="#document-operations-dotnet/binary-memory"/>.
        </note>
        <p>
            Because binary data is arbitrary anyway, it is backward
            compatible with the old SDK regarding flags so that it can
            be read and written back and forth. Make sure it is not
            compressed in the old SDK and that the same encoding and
            decoding process is used on the application side to avoid
            data corruption.
        </p>
        <p>
            Here is some demo code that shows how to write and read raw
            data. The example writes binary data, reads it back, and
            then frees the pooled resources:
        </p>
        <codeblock outputclass="language-java"><![CDATA[// Create buffer out of a string
ByteBuf toWrite = Unpooled.copiedBuffer("Hello World", CharsetUtil.UTF_8);

// Write it
bucket.upsert(BinaryDocument.create("binaryDoc", toWrite));

// Read it back
BinaryDocument read = bucket.get("binaryDoc", BinaryDocument.class);

// Print it
System.out.println(read.content().toString(CharsetUtil.UTF_8));

// Free the resources
ReferenceCountUtil.release(read.content());]]></codeblock>
    </section>

    <section id="binary-memory">
        <title>Correctly managing buffers</title>
        <p>
            <codeph>BinaryDocument</codeph> allows users to get the
            rawest form of data out of Couchbase. It  exposes Netty's
            <codeph>ByteBuf</codeph>, byte buffers that can have various
            characteristics (on- or off-heap, pooled or unpooled). In
            general, buffers created by the SDK are pooled and off heap.
            You can disable the pooling in the
            <codeph>CouchbaseEnvironment</codeph> if you absolutely need
            that.
        </p>
        <p>
            As a consequence, the memory associated with the ByteBuf
            must be a little bit more managed by the developer than
            usual in Java.
        </p>
        <p>
            Most notably, these byte buffers are reference counted, and
            you need to know three main methods associated to buffer
            management:
            <ul><li>
                <codeph>refCnt()</codeph> gives you the current
                reference count. When it hits 0, the buffer is released
                back to its original pool, and it cannot be used
                anymore.
            </li>
            <li>
                <codeph>release()</codeph> will decrease the reference
                count by 1 (by default).
            </li>
            <li>
                <codeph>retain()</codeph> is the inverse of release,
                allowing you to prepare for multiple consumptions by
                external methods that you know will each release the
                buffer.
            </li></ul>
        </p>
        <p>
            You can also use
            <codeph>ReferenceCountUtil.release(something)</codeph> if
            you don't want to check if <codeph>something</codeph> is
            actually a <codeph>ByteBuf</codeph> (will do nothing if it's
            not something that is <apiname>ReferenceCounted</apiname>).
        </p>
        <note type="important">
            The SDK bundles the Netty dependency into a different
            package so that it doesn't clash with a dependency to
            another version of Netty you may have. As such, you need to
            use the classes and packages provided by the SDK
            (<codeph>com.couchbase.client.deps.io.netty</codeph>) when
            interacting with the API. For example, the
            <codeph>ByteBuf</codeph> for the content of a
            <codeph>BinaryDocument</codeph> is a
            <codeph>com.couchbase.client.deps.io.netty.buffer.ByteBuf</codeph>.
        </note>

        <p><b>What happens if I don't release?</b></p>
        <p>
            Basically, you leak memory... Netty will by default inspect
            a small percentage of <codeph>ByteBuf</codeph> creations and
            usage to try and detect leaks (in which case it will output
            a log, look for the "LEAK" keyword).
        </p>
        <p>
            You can tune that to be more eagerly monitoring all buffers
            by calling
            <codeph>ResourceLeakDetector.setLevel(PARANOID)</codeph>.
            <note type="important" >Note that this incurs quite an
                overhead and should only be activated in tests. In
                production (prod), setting it to
                <codeph>ADVANCED</codeph> is not as heavy as paranoid
                and can be a good middle ground.</note>
        </p>

        <p><b>What happens if I release twice (or the SDK releases once more after I do)?</b></p>
        <p>
            Netty will throw an
            <codeph>IllegalReferenceCountException</codeph>. The buffer
            that has RefCnt = 0 cannot be interacted with anymore since
            it means it has been freed back into the pool.
        </p>

        <p><b>When must I release?</b></p>
        <p>
            When the SDK creates a <codeph>BinaryDocument</codeph> for
            you, basically GET-type operations.
        </p>
        <p>
            Mutative operations, on the other hand, will take care of
            the buffer you pass in for you, at the time the buffer is
            written on the wire.
        </p>

        <p><b>When must I usually retain?</b></p>
        <p>
            When you do a write, the buffer will usually be released by
            the SDK calling <codeph>release()</codeph>. But if you
            implement a kind of fallback behavior (for instance attempt
            to <codeph>insert()</codeph> a doc, catch
            <codeph>DocumentAlreadyExistException</codeph> and then
            fallback to an <codeph>update()</codeph> instead), that
            means the SDK would attempt to release twice, which won't
            work.
        </p>
        <p>
            In this case you can <codeph>retain()</codeph> the buffer
            before the first attempt, let the catch block do the extra
            release if something goes wrong. You have to manage the
            extra release if the first write succeeds, and think about
            catching other possible exceptions (here also an extra
            release is needed):
        </p>
<codeblock outputclass="language-java"><![CDATA[byteBuffer.retain(); //prepare for potential multi usage (+1 refCnt, refCnt = 2)
try {
   bucket.append(document);
   // refCnt = 2 on success
   byteBuffer.release(); //refCnt = 1
} catch (DocumentDoesNotExistException dneException) {
   // buffer is released on errors, refCnt = 1
   //second usage will also release, but we want to be at refCnt = 1 for the finally block
   byteBuffer.retain(); //refCnt = 2
   bucket.insert(document); //refCnt = 1
} // other uncaught errors will still cause refCnt to be released down to 1
finally {
   //we made sure that at this point refCnt = 1 in any case (success, caught exception, uncaught exception)
   byteBuffer.release(); //refCnt = 0, returned to the pool
}]]></codeblock>
    </section>

    </body>
</topic>
